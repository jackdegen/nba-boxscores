{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638e0909-439e-414d-a570-ca729cd1c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import unidecode\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections.abc import Sequence\n",
    "from functools import cache\n",
    "from typing import Any\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from engineFD import EngineFD\n",
    "from engineDK import EngineDK\n",
    "from filing import Filing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46e67c7-29bc-4459-86fb-8915cd87619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 350\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_colwidth = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2caf3b4-1cb8-44b9-8913-2c83fc3b69a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class PastPerformances:\n",
    "    def clean_name(cls, name: str) -> str:\n",
    "        \"\"\"\n",
    "        Standardizes name across PFR, FD, DK\n",
    "        \"\"\"\n",
    "        return ' '.join(name.split(' ')[:2]).replace('.', '')\n",
    "\n",
    "    def flatten(cls, nestedSeq: Sequence[Sequence[Any,...], ...], **kwargs) -> list[Any,...]:\n",
    "        \"\"\"\n",
    "        Takes 2d sequence and returns all values in 1d\n",
    "        Example: [(a,b,c), (a,y,z), (a,b,z)] -> [a, b, c, a, y, z, a, b, z]\n",
    "        TODO: kwargs to add functinoality\n",
    "            - unique: [(a,b,c), (a,y,z), (a,b,z)] -> [a, b, c, y, z]\n",
    "            - counts dict -> {a: 3, b: 2, z: 2, c: 1, z: 1} (recursive)\n",
    "            - etc\n",
    "        \"\"\"\n",
    "        if kwargs.get('unique', False):\n",
    "            return set(cls.flatten(nestedSeq))\n",
    "\n",
    "        return [element for innerSeq in nestedSeq for element in innerSeq]\n",
    "\n",
    "    def second_min(cls, seq: Sequence[int|float, ...]) -> int|float:\n",
    "        \"\"\"\n",
    "        Takes numerical sequence and returns second minimum value\n",
    "        \"\"\"\n",
    "        minimum = min(seq)\n",
    "        return min([val for val in seq if val != minimum])\n",
    "\n",
    "    def third_min(cls, seq: Sequence[int|float, ...]) -> int|float:\n",
    "        \"\"\"\n",
    "        Takes numerical sequence and returns third minimum value\n",
    "        \"\"\"\n",
    "        minimum = min(seq)\n",
    "        secondmin = cls.second_min(seq)\n",
    "        return min([val for val in seq if val not in (minimum, secondmin)])\n",
    "\n",
    "\n",
    "    def second_max(cls, seq: Sequence[int|float, ...]) -> int|float:\n",
    "        \"\"\"\n",
    "        Takes numerical sequence and returns second maximum value\n",
    "        \"\"\"\n",
    "        maximum = max(seq)\n",
    "        return max([val for val in seq if val != maximum])\n",
    "\n",
    "    def third_max(cls, seq: Sequence[int|float, ...]) -> int|float:\n",
    "        \"\"\"\n",
    "        Takes numerical sequence and returns third maximum value\n",
    "        \"\"\"\n",
    "        maximum = max(seq)\n",
    "        secondmax = cls.second_max(seq)\n",
    "        return max([val for val in seq if val not in (maximum, secondmax)])\n",
    "\n",
    "    def get_contest_files_with_n_games(cls, *, site: str, contest_files: list[str,...], n_games: int, **kwargs) -> list[str,...]:\n",
    "        \"\"\"\n",
    "        Takes a list of contest files and an integer as an input and searches all input files for those with that number of games\n",
    "        As of right now, only compatible with 2022-2023 season\n",
    "        Defaults:\n",
    "            - site: FanDuel\n",
    "            - mode: main-slate\n",
    "            - TODO: option for late slate\n",
    "        \"\"\"\n",
    "    \n",
    "        # Cushion added to include similar sized slates\n",
    "        # n_teams = range((n_games-1)*2, (n_games+1)*2 + 1) if n_games > 4 else (n_games*2, )\n",
    "        n_teams = (n_games*2, )\n",
    "    \n",
    "        team_column = 'Team' if site == 'fanduel' else 'TeamAbbrev'\n",
    "        \n",
    "        n_games_files = [\n",
    "            file for file in contest_files\n",
    "            if len(pd.read_csv(file)[team_column].drop_duplicates()) in n_teams\n",
    "        ]\n",
    "    \n",
    "        return n_games_files\n",
    "\n",
    "    \n",
    "    @cache\n",
    "    def extract_date(self, file: str):\n",
    "        \"\"\"\n",
    "        Extracts the date from a file\n",
    "        \"\"\"\n",
    "        return file.split('/')[-1].split('.')[0] #.replace('') #.replace('a', '').replace('b', '').replace('-late', '')\n",
    "\n",
    "    def __init__(self, *, n_games: int, **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Creates instance of class to analyze past performances\n",
    "        Defaults if not given:\n",
    "            - site: FanDuel\n",
    "            - contest: Main-Slate\n",
    "            - season: 2022-2023 Season\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_games = n_games\n",
    "\n",
    "        self.min_fpts = kwargs.get('min_fpts', 45.0)\n",
    "        self.min_fpts_1k = kwargs.get('min_fpts_1k', 6.0)\n",
    "\n",
    "        if n_games < 5:\n",
    "            self.min_fpts = 25.0\n",
    "            self.min_fpts_1k = 4.0\n",
    "\n",
    "        if kwargs.get('late_slate', False):\n",
    "            self.min_fpts = 20.0\n",
    "            self.min_fpts_1k = 6.0\n",
    "        \n",
    "        self.site = kwargs.get('site', 'fanduel')\n",
    "        self.contest = kwargs.get('contest', 'main-slate')\n",
    "\n",
    "        self.year = kwargs.get('year', 2022)\n",
    "        self.season = f'{self.year}-{self.year+1}'\n",
    "\n",
    "        self.filing = Filing(self.season)\n",
    "\n",
    "        # All contest files saved for year and mode\n",
    "        self.contest_files = glob.glob(os.path.join(self.filing.season_dir, 'contest-files', self.site, self.contest) + '/*.csv')\n",
    "        \n",
    "        # All boxscores for year\n",
    "        self.boxscore_files = glob.glob(self.filing.boxscores_dir + '/*.csv')\n",
    "\n",
    "\n",
    "        # Files will create optimals for\n",
    "\n",
    "        \n",
    "        self.n_games_files = glob.glob(os.path.join(self.filing.season_dir, 'contest-files', self.site, f'{self.n_games}-games') + '/*.csv')\n",
    "\n",
    "        n_games_p1_path = os.path.join(self.filing.season_dir, 'contest-files', self.site, f'{self.n_games+1}-games')\n",
    "        self.n_games_p1_files = glob.glob(n_games_p1_path + '/*.csv') if os.path.exists(n_games_p1_path) else list()\n",
    "\n",
    "        n_games_m1_path = os.path.join(self.filing.season_dir, 'contest-files', self.site, f'{self.n_games-1}-games')\n",
    "        self.n_games_m1_files = glob.glob(n_games_m1_path + '/*.csv') if os.path.exists(n_games_m1_path) else list()\n",
    "        \n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "    def get_boxscores_on_date(self, date: str) -> list[str,...]:\n",
    "        \"\"\"\n",
    "        Returns all file paths for boxscores from given date\n",
    "        As of rn, boxscores are saved for individual teams rather than all in one date (TODO: change?)\n",
    "        Will be used in conjuction with pd.concat\n",
    "\n",
    "        \"\"\"\n",
    "        return [file for file in self.boxscore_files if date in file]\n",
    "\n",
    "    \n",
    "    def load_boxscore_data(self, files: list[str,...]) -> dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Takes list of paths to boxscores CSV files as input\n",
    "        If error occuring with no items to concat, make sure current date's contest is not in n-games folder\n",
    "        \"\"\"\n",
    "        return {\n",
    "            self.extract_date(file): (pd\n",
    "                                      .concat([pd.read_csv(date_file) for date_file in self.get_boxscores_on_date(self.extract_date(file))])\n",
    "                                      .assign(\n",
    "                                          fpts=lambda df_: df_.fd_fpts if self.site == 'fanduel' else df_.dk_fpts,\n",
    "                                          # name=lambda df_: unidecode.unidecode(df_.name.str)\n",
    "                                      )\n",
    "                                      [['date', 'name', 'team', 'opp', 'starter', 'mp', 'pace', 'fpts']]\n",
    "                                     )\n",
    "            for file in files\n",
    "        }\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Creates dataframes that can be plugged into optimizer for all dates where self.n_games were played\n",
    "        Need FPTS and possible other info from boxscores csv files\n",
    "        Need Position and Salary from contest csv files\n",
    "        Therefore need to merge the two corresponding dfs for each date\n",
    "        \"\"\"\n",
    "\n",
    "        # Combined boxscores for all dates where self.n_games were played\n",
    "        # boxscore_dfs = self.load_boxscore_data(self.n_games_files)\n",
    "\n",
    "        boxscore_dfs = {\n",
    "            **self.load_boxscore_data(self.n_games_files),\n",
    "            # **self.load_boxscore_data(self.n_games_p1_files),\n",
    "            # **self.load_boxscore_data(self.n_games_m1_files)\n",
    "        } if self.n_games != 2 else self.load_boxscore_data(self.n_games_files)\n",
    "\n",
    "\n",
    "        # Contest files for dates where self.n_games were played\n",
    "        #Issue here? Trying to target late slate contests\n",
    "        # contest_files = [file for file in self.contest_files if self.extract_date(file) in boxscore_dfs]\n",
    "\n",
    "        # Fixed: Changed location from which reading contest-files, renamed 2 game contests to be just date (to match boxscore) and assigned to new directory in sandbox.ipynb\n",
    "        # Above ^(commented out)^ because self.contest_files refers to directory with all contest files, in the case of wanting to target 2 game contests, need to target files that originally have -late in name, was instead reading main-slate contests\n",
    "        contest_files = [file for file in self.n_games_files if self.extract_date(file) in boxscore_dfs]\n",
    "\n",
    "        # contest_files = sum([\n",
    "        #     # Contest files for dates where self.n_games were played\n",
    "        #     [file for file in self.contest_files if self.extract_date(file) in self.load_boxscore_data(self.n_games_files)],\n",
    "            \n",
    "        #     # Contest files for dates where self.n_games+1 were played\n",
    "        #     [file for file in self.contest_files if self.extract_date(file) in self.load_boxscore_data(self.n_games_p1_files)],\n",
    "            \n",
    "        #     # Contest files for dates where self.n_games-1 were played\n",
    "        #     [file for file in self.contest_files if self.extract_date(file) in self.load_boxscore_data(self.n_games_m1_files)]\n",
    "                                                                                                       \n",
    "        # ], list())\n",
    "\n",
    "        contest_columns = {\n",
    "            'draftkings': ['Name', 'Salary', 'Position', 'TeamAbbrev'],\n",
    "            'fanduel': ['Nickname', 'Salary', 'Position', 'Team']\n",
    "        }\n",
    "\n",
    "        contest_dfs = {\n",
    "            self.extract_date(file): (pd\n",
    "                                      .read_csv(file)\n",
    "                                      [contest_columns[self.site]]\n",
    "                                      .set_axis(['name', 'salary', 'pos', 'team'], axis=1)\n",
    "                                      .assign(date=self.extract_date(file))\n",
    "                                     )\n",
    "            for file in contest_files\n",
    "        }\n",
    "\n",
    "        # Create dataframes able to be plugged into optimizer\n",
    "        self.optimizer_dfs = dict()\n",
    "\n",
    "        # Identical keys so doesn't matter\n",
    "        for date in contest_dfs:\n",
    "            # Naming could be a little confusing, TODO: fix this\n",
    "            boxscore_df, contest_df = boxscore_dfs[date], contest_dfs[date]\n",
    "\n",
    "            # Sanitize names from boxscores\n",
    "            boxscore_df['name'] = boxscore_df['name'].map(lambda name: unidecode.unidecode(name))\n",
    "\n",
    "            # boxscore_df['game'] = boxscore_df[['team', 'opp']]\n",
    "\n",
    "            boxscore_df['index_'] = boxscore_df[['date', 'name']].apply(lambda row: f'{row.iloc[0]}_{row.iloc[1]}')\n",
    "            contest_df['index_'] = contest_df[['date', 'name']].apply(lambda row: f'{row.iloc[0]}_{row.iloc[1]}')\n",
    "\n",
    "            # number of games on slate\n",
    "            # slate_games = int()\n",
    "        \n",
    "            boxscore_df = boxscore_df.set_index('index_')\n",
    "            contest_df = contest_df.set_index('index_')\n",
    "\n",
    "            # Creates optimizer df with cutoff for fpts because will probably be too large for optimizer\n",
    "            \n",
    "            # Issues are with file naming\n",
    "            # If players are greater than min_fpts, have to be at least 5.0 fpts_1k\n",
    "            # if len(contest_df['team'].drop_duplicates()) == self.n_games * 2:\n",
    "            self.optimizer_dfs[date] = (boxscore_df\n",
    "                                        .merge(contest_df.loc[:, ['name', 'salary', 'pos']])\n",
    "                                        .dropna() # ??\n",
    "                                        .set_index('name')\n",
    "                                        .sort_values('fpts', ascending=False)\n",
    "                                        .assign(\n",
    "                                            fpts_1k=lambda df_: 1_000 * df_.fpts / df_.salary,\n",
    "                                            slate_games=len(contest_df['team'].drop_duplicates()) // 2\n",
    "                                        )\n",
    "                                        .pipe(lambda df_: df_.loc[((df_['fpts'] >= self.min_fpts)) | ((df_['fpts'] < self.min_fpts) & (df_['fpts_1k'] >= self.min_fpts_1k))])\n",
    "                                        # .pipe(lambda df_: df_.loc[((df_['fpts'] >= self.min_fpts) & (df_['fpts_1k'] >= 5.0)) | ((df_['fpts'] < self.min_fpts) & (df_['fpts_1k'] >= self.min_fpts_1k))])\n",
    "                                        .head(25)\n",
    "                                        .round(3)\n",
    "                                       )\n",
    "\n",
    "        self.optimizer_dfs = {date: date_df for date, date_df in self.optimizer_dfs.items() if not date_df.empty}\n",
    "                    \n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "    def create_optimal(self, data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Creates optimal for specific date\n",
    "        data is self.optimizer_dfs[date]\n",
    "        \"\"\"\n",
    "        engine = {'draftkings': EngineDK, 'fanduel': EngineFD}[self.site](data)\n",
    "\n",
    "        optimal = engine.create_lineups(top_n=10).reset_index(drop=True)\n",
    "\n",
    "        if 'lineup' not in optimal.columns:\n",
    "            optimal['lineup'] = optimal[engine.labels].apply(tuple, axis=1)\n",
    "            \n",
    "        optimal['lineup'] = optimal['lineup'].map(lambda names: engine.checker.order(names))\n",
    "\n",
    "        optimal['n_teams'] = optimal['lineup'].map(lambda names: len(set([engine.checker.pvalue(name, 'team') for name in names])))\n",
    "        optimal['n_starters'] = optimal['lineup'].map(lambda names: sum([engine.checker.pvalue(name, 'starter') for name in names]))\n",
    "        optimal['n_games'] = optimal['lineup'].map(lambda names: len(set([engine.checker.pvalue(name, 'game') for name in names])))\n",
    "\n",
    "\n",
    "        optimal['teams'] = optimal['lineup'].map(lambda names: '-'.join([engine.checker.pvalue(name, 'team') for name in names]))\n",
    "        optimal['games'] = optimal['lineup'].map(lambda names: ':'.join([engine.checker.pvalue(name, 'game') for name in names]))\n",
    "\n",
    "        optimal['distro'] = optimal['teams'].map(lambda teams: tuple(sorted([teams.split('-').count(team) for team in set(teams.split('-'))])))\n",
    "        optimal['game-distro'] = optimal['games'].map(lambda games: tuple(sorted([games.split(':').count(team) for team in set(games.split(':'))])))\n",
    "\n",
    "        optimal['salaries'] = optimal['lineup'].map(lambda names: tuple(sorted([engine.checker.pvalue(name, 'salary') for name in names])))\n",
    "        optimal['minutes'] = optimal['lineup'].map(lambda names: tuple(sorted([engine.checker.pvalue(name, 'mp') for name in names])))\n",
    "\n",
    "        # optimal['mt1_player'] = optimal['teams'].map(lambda teams: tuple([team for team in teams.split('-') if teams.count(team) > 1]))\n",
    "        # optimal['teammates'] = optimal[['lineup', 'mt1_player']].apply(lambda row: tuple([name for name in row.iloc[0] if engine.checker.pvalue(name, 'team') in row.iloc[1]]), axis=1)\n",
    "        # optimal['teammate_pos'] = optimal['teammates'].map(lambda names: tuple([engine.checker.pvalue(name, 'pos') for name in names]))\n",
    "        \n",
    "        optimal['C-salary'] = optimal['C'].map(lambda name: engine.checker.pvalue(name,'salary'))\n",
    "\n",
    "        \n",
    "        # optimal['min_salary'] = optimal['lineup'].map(lambda names: min([engine.checker.pvalue(name, 'salary') for name in names]))\n",
    "        # optimal['min2_salary'] = optimal['lineup'].map(lambda names: self.second_min([engine.checker.pvalue(name, 'salary') for name in names]))\n",
    "        # optimal['min3_salary'] = optimal['lineup'].map(lambda names: self.third_min([engine.checker.pvalue(name, 'salary') for name in names]))\n",
    "        \n",
    "        # optimal['max_salary'] = optimal['lineup'].map(lambda names: max([engine.checker.pvalue(name, 'salary') for name in names]))\n",
    "        # optimal['max2_salary'] = optimal['lineup'].map(lambda names: self.second_max([engine.checker.pvalue(name, 'salary') for name in names]))\n",
    "        # optimal['max3_salary'] = optimal['lineup'].map(lambda names: self.third_max([engine.checker.pvalue(name, 'salary') for name in names]))\n",
    "        \n",
    "\n",
    "        return optimal.drop('lineup', axis=1)\n",
    "\n",
    "\n",
    "    def create_optimals(self):\n",
    "\n",
    "        if not hasattr(self, 'optimizer_dfs'):\n",
    "            self.load_data()\n",
    "\n",
    "        # Did not do dictcomp so progress_bar possible\n",
    "        # self.optimals = dict()\n",
    "\n",
    "        # for date, date_data in tqdm(self.optimizer_dfs.items()):\n",
    "        #     self.optimals[date] = self.create_optimal(date_data)\n",
    "\n",
    "        self.optimals = {date: self.create_optimal(date_data) for date, date_data in tqdm(self.optimizer_dfs.items())}\n",
    "\n",
    "\n",
    "        return None\n",
    "\n",
    "    def view_optimal(self, date: str) -> pd.DataFrame:\n",
    "\n",
    "        if hasattr(self, 'optimals'):\n",
    "            return self.optimals[date]\n",
    "\n",
    "        if not hasattr(self, 'optimizer_dfs'):\n",
    "            self.load_data()\n",
    "\n",
    "        return self.create_optimal(self.optimizer_dfs[date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e377b354-f68e-4c44-ad80-991a9e6cfe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YESTERDAY = datetime.datetime.strftime((datetime.datetime.now() - datetime.timedelta(days=1)), '%Y-%m-%d')\n",
    "# pp23 = PastPerformances(year=2023, n_games=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed21cfc-9adf-4f8f-8b42-1ff4b8af712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp23 = PastPerformances(year=2023, n_games=2, site='draftkings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07d0292d-534c-49f1-94cc-f75a624a59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp23.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1d755e-48b2-4479-bc66-49868799b300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pp23.optimizer_dfs #[YESTERDAY]\n",
    "len(pp23.optimizer_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33358695-8449-4e5e-b48a-f1c1b8281c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27f119a37a444faa1600cc4237371a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pp23.create_optimals()\n",
    "# pp23.optimals #[YESTERDAY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e3485-cd06-4b0a-8dc8-9c592b793a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimals = (pd\n",
    "            .concat(pp23.optimals.values())\n",
    "            .drop(['teams', 'minutes', 'games'], axis=1)\n",
    "            # .pipe(lambda df_: df_.loc[df_.index.isin(range(5))])\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf8db07-5721-454e-a65f-cc932150f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11050c6a-213f-4792-937f-9e2856c7728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0628db6f-c11f-4bb6-9526-ad8aab7c3899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def report() -> None:\n",
    "    \"\"\"\n",
    "    Reports outcome of optimals crunch\n",
    "    \"\"\"\n",
    "    sample_size = len(pp23.optimizer_dfs)\n",
    "    target_rows = sample_size * 10\n",
    "\n",
    "    rows = optimals.shape[0]\n",
    "    output = list()\n",
    "    \n",
    "    try:\n",
    "        assert(rows == target_rows)\n",
    "        output.append('Optimals successful for all samples')\n",
    "\n",
    "    except AssertionError:\n",
    "        missing = target_rows - rows\n",
    "        days_missing = missing // 10\n",
    "        output.append(f'Missing {days_missing} optimal slate{\"\" if days_missing == 1 else \"s\"}')\n",
    "\n",
    "    print(*output, sep='\\n')\n",
    "    return\n",
    "\n",
    "report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461dbf4-a954-413c-835b-af3587817599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentages(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Takes a series and returns edited values_counts\n",
    "    \"\"\"\n",
    "    return s.value_counts(normalize=True).round(3) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fec4a-3856-4897-8c86-277c89dc76c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(optimals['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713eb5a-928b-42bd-8b62-576dd20daba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimals['max-salary'] = optimals['salaries'].map(lambda sals: max(sals))\n",
    "optimals['max-salary-2'] = optimals['salaries'].map(lambda sals: sorted(sals)[-2])\n",
    "optimals['max-salary-3'] = optimals['salaries'].map(lambda sals: sorted(sals)[-3])\n",
    "\n",
    "optimals['sum-max-2-sals'] = optimals['max-salary'] + optimals['max-salary-2']\n",
    "optimals['sum-max-3-sals'] = optimals['sum-max-2-sals'] + optimals['max-salary-3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0bb1d0-265f-458d-9251-f789f3d4f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(optimals['max-salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94603f92-15cc-44ee-a825-becfa60a98fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(optimals['max-salary-2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47cf0ac-6662-4022-9f74-980d656e29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(optimals['max-salary-3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51634c41-51bf-4153-8893-f75220a15e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(optimals['sum-max-2-sals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ed6ed-73e9-44b6-bf7b-f11d4fbe52b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(optimals['sum-max-3-sals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84ca89-6791-423a-addc-5934d6db39c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(optimals['n_games'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26aa0c42-f7c5-40d8-a99d-5988f5269910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 3)    41.8\n",
       "(1, 2, 2, 4)    20.3\n",
       "(2, 2, 2, 3)    16.4\n",
       "(2, 3, 4)       10.0\n",
       "(1, 1, 3, 4)     7.9\n",
       "(3, 3, 3)        2.7\n",
       "(1, 4, 4)        0.9\n",
       "Name: distro, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentages(optimals['distro']) #.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a18ac2d-9240-4b32-b0a4-7aec3e9072e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)    63.6\n",
       "(3, 6)    32.1\n",
       "(2, 7)     4.2\n",
       "Name: game-distro, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentages(optimals['game-distro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ea00244-7799-4af9-a6c4-3636860d59d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    86.4\n",
       "3    13.6\n",
       "Name: n_teams, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentages(optimals['n_teams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81d235-4f1f-4ec0-acc5-b7ec3fa25bf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "percentages(optimals['C-salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e785e9b2-0e3b-40f3-be45-9d4bdd94a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sals = (pd\n",
    "           .DataFrame(optimals['salaries'].value_counts(normalize=True))\n",
    "           .reset_index()\n",
    "           .set_axis(['sals', '%'], axis=1)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19af3b-4416-4972-a3b5-253010d0b1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f722d-4168-4b4a-86b3-320b2a00e298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e949dfe-dbad-4754-9262-fb93a43bc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sals['max'] = df_sals['sals'].map(lambda sals: max(sals))\n",
    "df_sals['min'] = df_sals['sals'].map(lambda sals: min(sals))\n",
    "\n",
    "df_sals = df_sals.sort_values('max', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b883ab98-f387-4be0-839d-d49fd17da9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sals['lt4k'] = df_sals['sals'].map(lambda sals: len([sal for sal in sals if sal < 4_000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a5738-a1ad-440c-9f45-5791f8d0d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sals['lt5k'] = df_sals['sals'].map(lambda sals: len([sal for sal in sals if sal < 5_000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f5338-3b5f-465b-b939-d9e63c3bd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sals['lt6k'] = df_sals['sals'].map(lambda sals: len([sal for sal in sals if sal < 6_000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f2d110-34df-4e0f-88a3-c901c2916ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sals['lt7k'] = df_sals['sals'].map(lambda sals: len([sal for sal in sals if sal < 7_000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7706d1a-a7d2-4c78-bff2-c83e3026defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['lt4k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f426e-5336-45da-828a-f28100044ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['lt5k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9337c-0a81-4616-90ff-def6a2d882e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['lt6k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98ddba-8b4e-4e09-87ee-fe1049143013",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['lt7k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a91a51-20a5-41ac-ab54-d23bbbfe5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0cad3-823e-4a53-a22d-74bfeaac5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb006e3-41de-44fe-911e-bcd41f8b8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sals = df_sals['min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ba649-ec95-40f9-9e75-ab08918c308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_4kmin = [sal for sal in min_sals if sal < 4_000 or sal >= 5_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e95ec-f80e-4d29-9c49-6608e0dab6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sals_perc = percentages(df_sals['min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a4033b-d00f-4540-acb8-d535f4c7567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sals_perc[list(set(not_4kmin))].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6521a-8d02-4d45-9ce5-68dc5e132fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71f7b2-1344-4448-8103-7fa922cd5c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76732b3f-c3a8-4d03-ae5a-d727f2e4ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sals['sals'] = df_sals['sals'].map(lambda distro: tuple([str(sal)[:-3] for sal in distro]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5006aa-ae58-4122-ba81-e2f37e88ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sals['minsal'] = df_sals['sals'].map(lambda sals: min([int(sal_) for sal_ in sals]))\n",
    "percentages(df_sals['minsal'])\n",
    "# df_sals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea80f0-54d1-42c1-b67a-2fb3bf81c479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7fee92-52a8-4cf3-9c4a-07168f7a2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for str_n in [str(n) for n in (3,4,5,6,7,8,9,10,11)]:\n",
    "    df_sals[str_n] = df_sals['sals'].map(lambda sals: int(str_n in sals))\n",
    "    df_sals[f'{str_n}-counts'] = df_sals['sals'].map(lambda sals: sals.count(str_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b7da20-e16f-4729-8aa5-13e879e71b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sals['3-4-counts'] = df_sals['sals'].map(lambda sals: sum([sals.count('3'), sals.count('4')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289ec25-d5be-4a66-9ebf-6b9adaeb1299",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['3-4-counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc3f577-8f1b-479a-bc24-0c9879d0dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cols = [col for col in df_sals.columns if 'counts' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7672aa2a-b341-46ec-9401-4e25a9dd3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['3-counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b031a71-70d2-4f5f-9411-00db146ec906",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['4-counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2f3c5-3928-43e3-a3d0-28160a8f076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['5-counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e10923-6978-4ac1-a220-3a305895972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['6-counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277cbbf-e569-480c-9e61-0e6f3f76815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['7-counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43bade5-3d12-4f7b-9225-7fb36de5a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['8-counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f897786-2cde-411b-af81-9e3d0fe8c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['9-counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72ea87-0fc8-460f-bfa1-d27b28d03a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(df_sals['10-counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22c6c9-d85f-4aa4-8f0e-d8cdfb35de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(optimals['max_salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b787fbd-0fd0-4317-8c74-e923aa17f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(optimals['min_salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b8e20-d2ae-4aa7-9803-a2055d2a64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages(optimals['distro'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
